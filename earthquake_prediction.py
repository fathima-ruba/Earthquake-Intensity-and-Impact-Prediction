# -*- coding: utf-8 -*-
"""Earthquake Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dZc3sXi31wqwerdMOlJmE_SQQhJDpjVX
"""

import zipfile
import os

# Define the path to the uploaded zip file
zip_file_path = '/content/Earthquake.zip'
unzip_folder_path = '/content/Earthquake'

if not os.path.exists(unzip_folder_path):
    os.makedirs(unzip_folder_path)

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(unzip_folder_path)

# Contents of the unzipped folder
unzipped_contents = os.listdir(unzip_folder_path)
unzipped_contents

import pandas as pd

# Load the first few rows of each CSV file to give an overview of the data
file_previews = {}

for file_name in unzipped_contents:
    file_path = os.path.join(unzip_folder_path, file_name)
    df_preview = pd.read_csv(file_path, nrows=5)  # Read only the first 5 rows for a preview
    file_previews[file_name] = df_preview

file_previews

# Import necessary libraries for data exploration
import matplotlib.pyplot as plt
import seaborn as sns

# Load the entire datasets for exploration
file_paths = {file_name: os.path.join(unzip_folder_path, file_name) for file_name in unzipped_contents}
datasets = {file_name: pd.read_csv(file_path) for file_name, file_path in file_paths.items()}

# Show basic statistics for each dataset
basic_stats = {file_name: dataset.describe() for file_name, dataset in datasets.items()}

# Show the distribution of the 'magnitude' feature, as it's a key variable for earthquake intensity
plt.figure(figsize=(12, 6))
for file_name, dataset in datasets.items():
    sns.histplot(dataset['magnitude'], kde=True, label=file_name)
plt.title('Distribution of Earthquake Magnitude')
plt.xlabel('Magnitude')
plt.ylabel('Frequency')
plt.legend()
plt.show()

basic_stats

"""# Data Exploration Summary

# Basic Statistics

For both datasets (earthquake_1995-2023.csv and earthquake_data.csv), here are some key statistics:

magnitude: Ranges roughly from 6.5 to 9.1, with a mean around 6.94.

cdi (Community Internet Intensity Map): Ranges from 0 to 9, indicating the perceived intensity of the earthquake.

mmi (Modified Mercalli Intensity): Ranges from 1 to 10, providing another measure of earthquake intensity.

tsunami: Binary feature indicating if a tsunami was generated (1) or not (0).

sig (Significance): A composite value for the earthquake event, which varies widely.

nst: Number of stations contributing to the event.

dmin: Minimum distance to the earthquake event.

gap: Azimuthal gap for the event.

depth: Depth of the earthquake, varying widely.

latitude and longitude: Geographical coordinates of the earthquake.

# Magnitude Distribution

The histogram of earthquake magnitudes shows that most earthquakes are in the range of 6.5 to 7.5, which is considered strong but not extremely catastrophic.
"""

# Data Preprocessing

# Check for missing values in both datasets
missing_values = {file_name: dataset.isnull().sum() for file_name, dataset in datasets.items()}

# For columns with missing values, we have options to fill them:
# - For numerical columns, we can use mean or median.
# - For categorical columns, we can use the mode or a special category like 'Unknown'.

# Filling missing values with appropriate methods
for file_name, dataset in datasets.items():
    for col in dataset.columns:
        if dataset[col].dtype == 'object':
            dataset[col].fillna('Unknown', inplace=True)
        else:
            dataset[col].fillna(dataset[col].median(), inplace=True)

# Confirm that there are no missing values
missing_values_check = {file_name: dataset.isnull().sum() for file_name, dataset in datasets.items()}

missing_values_check

from sklearn.preprocessing import LabelEncoder

# Feature Engineering

# Select important features for predicting earthquake intensity and impact.
selected_features = ['magnitude', 'cdi', 'mmi', 'tsunami', 'sig', 'nst', 'dmin', 'gap', 'depth', 'latitude', 'longitude']

# Extracting selected features from both datasets
feature_dfs = {file_name: dataset[selected_features] for file_name, dataset in datasets.items()}

# Label encoding for categorical variables ('alert')
# Although 'alert' is a categorical variable, it has ordinal characteristics (green < yellow < red).
# We can convert it into numerical form using label encoding.
label_encoder = LabelEncoder()

for file_name, dataset in datasets.items():
    dataset['alert'] = label_encoder.fit_transform(dataset['alert'])
    feature_dfs[file_name]['alert'] = dataset['alert']

# Show the first few rows of the feature-selected dataframes
feature_previews = {file_name: dataset.head() for file_name, dataset in feature_dfs.items()}

feature_previews

"""# Selected Features:

magnitude: Magnitude of the earthquake

cdi: Community Internet Intensity Map

mmi: Modified Mercalli Intensity

tsunami: Indicates if a tsunami was generated

sig: Significance of the earthquake

nst: Number of stations contributing to the event

dmin: Minimum distance to the earthquake event

gap: Azimuthal gap for the event

depth: Depth of the earthquake

latitude and longitude: Geographical coordinates

alert: Alert level (encoded from categorical to numerical)

# We can consider the following machine learning models:

Linear Regression: A simple yet effective model for regression tasks.

Random Forest Regressor: An ensemble learning method that can capture complex relationships.

Support Vector Regressor (SVR): Suitable for capturing non-linear relationships.

# We'll use these models to predict two key variables related to earthquake impact:

Community Internet Intensity Map (CDI): This represents the human-perceived intensity of the earthquake.

Modified Mercalli Intensity (MMI): This is another measure of earthquake intensity, usually derived from instrumental data.

We'll split the data into training and test sets, train each model on the training set, and evaluate its performance on the test set.
"""

from sklearn.model_selection import train_test_split

# Data Splitting

# Choose one dataset for demonstration. Let's use 'earthquake_data.csv' for this example.
selected_dataset = feature_dfs['earthquake_data.csv']

# Define predictors (X) and target variables (y) for CDI and MMI
X = selected_dataset.drop(['cdi', 'mmi'], axis=1)
y_cdi = selected_dataset['cdi']
y_mmi = selected_dataset['mmi']

# Split the data into training and test sets for both CDI and MMI
X_train_cdi, X_test_cdi, y_train_cdi, y_test_cdi = train_test_split(X, y_cdi, test_size=0.2, random_state=42)
X_train_mmi, X_test_mmi, y_train_mmi, y_test_mmi = train_test_split(X, y_mmi, test_size=0.2, random_state=42)

# Show the size of the training and test sets
(X_train_cdi.shape, X_test_cdi.shape), (X_train_mmi.shape, X_test_mmi.shape)

"""The data has been successfully split into training and test sets for both CDI and MMI predictions.

# For CDI:
Training set: 625 samples
Test set: 157 samples
# For MMI:
Training set: 625 samples
Test set: 157 samples
"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

# Model Training and Evaluation

# Initialize the models
linear_reg = LinearRegression()
random_forest = RandomForestRegressor(random_state=42)
svr = SVR()

# Create a dictionary to store the models and their names
models = {'Linear Regression': linear_reg, 'Random Forest': random_forest, 'Support Vector Regressor': svr}

# Create a dictionary to store the results
results_cdi = {}
results_mmi = {}

# Train and evaluate models for predicting CDI
for name, model in models.items():
    # Train the model
    model.fit(X_train_cdi, y_train_cdi)

    # Make predictions on the test set
    y_pred_cdi = model.predict(X_test_cdi)

    # Evaluate the model (using Mean Squared Error)
    mse_cdi = mean_squared_error(y_test_cdi, y_pred_cdi)

    # Store the results
    results_cdi[name] = mse_cdi

# Train and evaluate models for predicting MMI
for name, model in models.items():
    # Train the model
    model.fit(X_train_mmi, y_train_mmi)

    # Make predictions on the test set
    y_pred_mmi = model.predict(X_test_mmi)

    # Evaluate the model (using Mean Squared Error)
    mse_mmi = mean_squared_error(y_test_mmi, y_pred_mmi)

    # Store the results
    results_mmi[name] = mse_mmi

results_cdi, results_mmi

"""# For Predicting CDI (Community Internet Intensity Map):
Linear Regression: MSE = 7.83

Random Forest: MSE = 3.21

Support Vector Regressor: MSE = 6.67
# For Predicting MMI (Modified Mercalli Intensity):
Linear Regression: MSE = 1.01

Random Forest: MSE = 0.83

Support Vector Regressor: MSE = 1.05

Lower MSE values indicate better model performance. Based on these results, the Random Forest model performs the best for both CDI and MMI predictions.
"""

# Prepare hypothetical real-time seismic data for prediction
from sklearn.ensemble import RandomForestRegressor

rf_model_cdi = RandomForestRegressor(random_state=42)
rf_model_cdi.fit(X_train_cdi, y_train_cdi)

rf_model_mmi = RandomForestRegressor(random_state=42)
rf_model_mmi.fit(X_train_mmi, y_train_mmi)

# Example data format: [magnitude, tsunami, sig, nst, dmin, gap, depth, latitude, longitude, alert]
hypothetical_data_cdi = [
    [6.5, 0, 600, 100, 0.5, 30, 50, 20.0, 120.0, 1],  # Hypothetical data point 1
    [7.0, 1, 700, 120, 1.0, 25, 100, 40.0, 130.0, 2]   # Hypothetical data point 2
]

hypothetical_data_mmi = [
    [6.2, 0, 580, 90, 0.4, 35, 45, 22.0, 122.0, 1],  # Hypothetical data point 1
    [7.1, 1, 710, 130, 1.1, 24, 110, 42.0, 132.0, 2]  # Hypothetical data point 2
]

# Convert to DataFrame for easier handling
hypothetical_df_cdi = pd.DataFrame(hypothetical_data_cdi, columns=X.columns)
hypothetical_df_mmi = pd.DataFrame(hypothetical_data_mmi, columns=X.columns)

# Make predictions using the trained Random Forest model
predicted_cdi = rf_model_cdi.predict(hypothetical_df_cdi)
predicted_mmi = rf_model_mmi.predict(hypothetical_df_mmi)

predicted_cdi, predicted_mmi

"""Based on the hypothetical real-time seismic data, the trained Random Forest model predicts the following:

# Predicted Intensity Values:
# For the first hypothetical data point:
CDI (Community Internet Intensity Map): 5.54

MMI (Modified Mercalli Intensity): 5.56
# For the second hypothetical data point:
CDI (Community Internet Intensity Map): 5.61

MMI (Modified Mercalli Intensity): 5.65

These predicted values provide an estimate of the earthquake's intensity and potential impact, which could be useful for early warning systems.
"""